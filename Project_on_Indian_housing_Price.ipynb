{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Project Title: Real Estate Investment Advisor: Predicting Property Profitability & Future Value\n",
        "\n"
      ],
      "metadata": {
        "id": "3oJl3mEnYN5m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Skills take away from this project"
      ],
      "metadata": {
        "id": "_l5pXCfzYpF5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Python, Machine Learning, EDA, Data Analysis, Feature Engineering, Regression, Classification, Streamlit, MLflow, Model Evaluation, Feature Scaling, Domain Understanding.\n",
        "\n"
      ],
      "metadata": {
        "id": "_jT3gHG2YvHD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GITHUB LINK\n",
        "https://github.com/tiwariabhi374-lang/Real-Investment-Projec"
      ],
      "metadata": {
        "id": "I8Z9CaC4W7hE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DOMAIN : Real Estate / Investment / Financial Analytics\n",
        "\n"
      ],
      "metadata": {
        "id": "amySlihKY6hB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem statement"
      ],
      "metadata": {
        "id": "OsaEkeFkamJ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Develop a machine learning application to assist potential investors in making real estate decisions. The system should:\n",
        "\n",
        "\n",
        "1.  Classify whether a property is a \"Good Investment\" (Classification).\n",
        "\n",
        "2.  Predict the estimated property price after 5 years (Regression).\n",
        "\n",
        "Use the provided dataset to preprocess and analyze the data, engineer relevant features, and deploy a user-interactive application using Streamlit that provides investment recommendations and price forecasts. MLflow will be used for experiment tracking.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zDGk3wNbayxV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Business Use Cases\n",
        "\n",
        "\n",
        "\n",
        "1.  Empower real estate investors with intelligent tools to assess long-term returns.\n",
        "\n",
        "\n",
        "1.  Support buyers in choosing high-return properties in developing areas.\n",
        "\n",
        "2.  Help real estate companies automate investment analysis for listings.\n",
        "\n",
        "\n",
        "2.   Improve customer trust in real estate platforms with data-backed predictions.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "r_4peRMgbXGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basics Libraries"
      ],
      "metadata": {
        "id": "P70B09PJcfpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as  np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "0ax0l_FBcdzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/india_housing_prices.csv\")"
      ],
      "metadata": {
        "id": "kVAFQoovcd3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "Z_rg4oqpcd_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "diWuib-QceCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "93uiqGhEdBZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# columns of the dataset\n",
        "df.columns"
      ],
      "metadata": {
        "id": "SkQwULFidBkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "lNmFyTPFdBmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.size"
      ],
      "metadata": {
        "id": "8_S9D6MsdBpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "aVIJGIUvdBr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## null values\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "p53u6U5DdBvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Description:\n",
        "1. ID : Unique identifier for each property record\n",
        "2. State : State where the property is located\n",
        "3. City : City of the property\n",
        "4. Locality : Specific neighborhood or locality\n",
        "5. Property_Type : Type of property (Apartment, Villa, House, etc.)\n",
        "6. BHK : Number of bedrooms, hall, kitchen\n",
        "7. Size_in_SqFt : Area of the property in square feet\n",
        "8. Price_in_Lakhs : Price of the property in lakhs (local currency)\n",
        "9. Price_per_SqFt : Price divided by area; normalized price metric\n",
        "10. Year_Built : Year when the property was constructed\n",
        "11. Furnished_Status : Furnishing level (Unfurnished, Semi, Fully)\n",
        "12. Floor_No : Floor number of the property\n",
        "13. Total_Floors : Total number of floors in the building\n",
        "14. Age_of_Property : Age of the property (Current Year - Year_Built)\n",
        "15. Nearby_Schools : Number or rating of nearby schools\n",
        "16. Nearby_Hospitals : Number of nearby hospitals\n",
        "17. Public_Transport_Accessibility : Access to buses/metro/train\n",
        "18. Parking_Space : Number of parking spots available\n",
        "19. Security : Security features (Gated, CCTV, Guard)\n",
        "20. Amenities : Amenities available (Gym, Pool, Clubhouse)\n",
        "21. Facing : Direction the property faces (North, South, etc.)\n",
        "22. Owner_Type : Owner type (Individual, Builder, Agent)\n",
        "23. Availability_Status : Current status (Available, Under Construction, Sold)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JM4QKF-edxP-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**APPROACH**"
      ],
      "metadata": {
        "id": "N5FUUwjtcESS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Data Processing"
      ],
      "metadata": {
        "id": "Y7DuQJSQcIt3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IzCH0WaVPZN"
      },
      "outputs": [],
      "source": [
        "# ---------------------------------------------\n",
        "# STEP 1 : DATA PREPROCESSING FOR HOUSING DATA\n",
        "# ---------------------------------------------\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load Dataset\n",
        "df = pd.read_csv(\"india_housing_prices.csv\")\n",
        "\n",
        "# -------------------------------\n",
        "# 1.1 HANDLE DUPLICATES & MISSING VALUES\n",
        "# -------------------------------\n",
        "\n",
        "# Remove duplicate rows\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Identify numerical and categorical columns\n",
        "num_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Impute numerical missing values with median\n",
        "num_imputer = SimpleImputer(strategy=\"median\")\n",
        "df[num_cols] = num_imputer.fit_transform(df[num_cols])\n",
        "\n",
        "# Store original (imputed) Price_in_Lakhs before scaling for target calculation\n",
        "# This ensures CAGR_5Y is not constant and uses meaningful price values\n",
        "df_original_price_for_target = df[\"Price_in_Lakhs\"].copy()\n",
        "\n",
        "# Impute categorical missing values with \"Unknown\"\n",
        "cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
        "df[cat_cols] = cat_imputer.fit_transform(df[cat_cols])\n",
        "\n",
        "# -------------------------------\n",
        "# 1.2 NORMALIZE / SCALE NUMERICAL FEATURES\n",
        "# -------------------------------\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "scaled_cols = [\"Size_in_SqFt\", \"Age_of_Property\", \"Price_in_Lakhs\"] # Price_in_Lakhs itself is scaled as a feature\n",
        "\n",
        "for col in scaled_cols:\n",
        "    if col in df.columns:\n",
        "        df[col] = scaler.fit_transform(df[[col]])\n",
        "\n",
        "# -------------------------------\n",
        "# 1.3 ENCODE CATEGORICAL FEATURES\n",
        "# -------------------------------\n",
        "\n",
        "# Frequency Encoding for high-cardinality columns\n",
        "if \"Locality\" in df.columns:\n",
        "    locality_freq = df[\"Locality\"].value_counts().to_dict()\n",
        "    df[\"Locality_Freq\"] = df[\"Locality\"].map(locality_freq)\n",
        "\n",
        "if \"City\" in df.columns:\n",
        "    city_freq = df[\"City\"].value_counts().to_dict()\n",
        "    df[\"City_Freq\"] = df[\"City\"].map(city_freq)\n",
        "\n",
        "# One-hot encoding for low-cardinality categorical features\n",
        "# Removed 'Property_Type' from low_card_cols so it remains for EDA plots\n",
        "low_card_cols = [\"State\", \"Availability_Status\"]\n",
        "\n",
        "df = pd.get_dummies(df, columns=[col for col in low_card_cols if col in df.columns],\n",
        "                    drop_first=True)\n",
        "\n",
        "# -------------------------------\n",
        "# 1.4 FEATURE ENGINEERING\n",
        "# -------------------------------\n",
        "\n",
        "# Price per SqFt\n",
        "# This will now use the scaled Price_in_Lakhs. (Note: if original Price_per_SqFt is desired, adjust here)\n",
        "if \"Price_in_Lakhs\" in df.columns and \"Size_in_SqFt\" in df.columns:\n",
        "    df[\"Price_per_SqFt_calculated\"] = (df[\"Price_in_Lakhs\"] / df[\"Size_in_SqFt\"]).replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# Amenities count\n",
        "if \"Amenities\" in df.columns:\n",
        "    df[\"Amenities_Count\"] = df[\"Amenities\"].apply(lambda x: len(str(x).split(\",\")))\n",
        "\n",
        "# Parking / Security binary encoding\n",
        "if \"Parking_Space\" in df.columns:\n",
        "    df[\"Has_Parking\"] = df[\"Parking_Space\"].apply(lambda x: 1 if str(x).lower() in [\"yes\", \"true\"] else 0)\n",
        "\n",
        "if \"Security\" in df.columns:\n",
        "    df[\"Has_Security\"] = df[\"Security\"].apply(lambda x: 1 if str(x).lower() in [\"yes\", \"true\"] else 0)\n",
        "\n",
        "# School Density Score\n",
        "if \"Nearby_Schools\" in df.columns:\n",
        "    df[\"School_Density_Score\"] = np.minimum(df[\"Nearby_Schools\"] / 5, 1)\n",
        "\n",
        "# -------------------------------\n",
        "# 1.5 CREATE LABEL: GOOD INVESTMENT\n",
        "# -------------------------------\n",
        "\n",
        "# Estimate future price using assumed annual growth rate.\n",
        "# To make CAGR_5Y dynamic and avoid a constant value,\n",
        "# we introduce a small random variation to the growth rate.\n",
        "DEFAULT_GROWTH_RATE = 0.06  # 6% default if city growth not estimated\n",
        "\n",
        "# Generate growth rates with a slight variation for each property\n",
        "# Use df_original_price_for_target (unscaled, imputed Price_in_Lakhs) for this calculation\n",
        "growth_rates = np.random.normal(DEFAULT_GROWTH_RATE, 0.01, len(df))\n",
        "# Clip growth rates to a reasonable range (e.g., 1% to 15%) to avoid extreme values\n",
        "growth_rates = np.clip(growth_rates, 0.01, 0.15)\n",
        "\n",
        "df[\"Estimated_Price_5Y\"] = df_original_price_for_target * ((1 + growth_rates) ** 5)\n",
        "\n",
        "# Compute CAGR based on generated Estimated_Price_5Y and original (unscaled) price\n",
        "df[\"CAGR_5Y\"] = ((df[\"Estimated_Price_5Y\"] / df_original_price_for_target) ** (1/5)) - 1\n",
        "\n",
        "# Create Good Investment label (threshold = 8%)\n",
        "df[\"Good_Investment\"] = df[\"CAGR_5Y\"].apply(lambda x: 1 if x >= 0.08 else 0)\n",
        "\n",
        "# -------------------------------\n",
        "# FINAL: PREPROCESSED DATA\n",
        "# -------------------------------\n",
        "\n",
        "df.to_csv(\"processed_housing_data.csv\", index=False)\n",
        "\n",
        "print(\"✅ Step 1 completed: processed_housing_data.csv saved successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights**\n",
        "\n",
        "\n",
        "*   In data Processing , we have handle missing values and remove duplicate rows.\n",
        "\n",
        "*   Normalize the price of the house according to the locality at a cheaper rate.\n",
        "*   Encode Categorical Features for locality and city.\n",
        "\n",
        "*   Feature Enginnering to calculate price in lakhs by size in square feet.\n",
        "\n"
      ],
      "metadata": {
        "id": "szZ0j9LCKRP7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Step 2: Exploratory Data Analysis (EDA)\n"
      ],
      "metadata": {
        "id": "L9YgJ9tWil6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd # Ensure pandas is imported\n",
        "\n",
        "# Explicitly load the processed data to ensure CAGR_5Y is available\n",
        "df = pd.read_csv(\"processed_housing_data.csv\")\n",
        "\n",
        "# Display settings\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (10, 5)\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Price Trends by City\n",
        "# -----------------------------\n",
        "\n",
        "city_price = df.groupby('City')['Price_in_Lakhs'].mean().sort_values(ascending=False)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "city_price.plot(kind='bar')\n",
        "plt.title(\"Average Property Price by City\")\n",
        "plt.ylabel(\"Average Price in Lakhs\")\n",
        "plt.xlabel(\"City\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Correlation between Area and Investment Return\n",
        "# -----------------------------\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(data=df, x='Size_in_SqFt', y='CAGR_5Y', hue='Good_Investment')\n",
        "plt.title(\"Size in SqFt vs. CAGR 5Y\")\n",
        "plt.xlabel(\"Size in SqFt\")\n",
        "plt.ylabel(\"CAGR 5Y\")\n",
        "plt.show()\n",
        "\n",
        "# Correlation value\n",
        "corr_area = df['Size_in_SqFt'].corr(df['CAGR_5Y'])\n",
        "print(\"Correlation between Size in SqFt and CAGR 5Y:\", corr_area)\n",
        "\n",
        "# Removed: Section for 'Crime_Rate' as the column is not available.\n",
        "\n",
        "# Removed: Section for 'Infrastructure_Score' and 'Resale_Value' as 'Infrastructure_Score' is not available.\n"
      ],
      "metadata": {
        "id": "3JnR64WEiho0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights**\n",
        "\n",
        "\n",
        "*   Prices in trends according to city . So average price in city and Average  price in Lakhs.\n",
        "\n",
        "*  Correlation between the Area and the investment return.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ni6sW-otMRDG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Distribution of Prices, Area, Price per Sqft, Outliers & Relationships"
      ],
      "metadata": {
        "id": "SynfZJ41ks3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Robust EDA: handles missing / variably-named columns gracefully\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd # Ensure pandas is imported if not already\n",
        "import numpy as np # Ensure numpy is imported if not already\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (10, 5)\n",
        "\n",
        "\n",
        "# Show available columns to help debugging\n",
        "print(\"Available columns:\", list(df.columns))\n",
        "\n",
        "# Helper to choose first matching column from candidates\n",
        "def get_col(df, candidates):\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "# Try common variants for the columns we need\n",
        "price_col = get_col(df, ['Price', 'Price_in_Lakhs', 'price', 'price_in_lakhs', 'TotalPrice'])\n",
        "area_col  = get_col(df, ['Area', 'Size_in_SqFt', 'Size', 'area', 'Builtup_Area', 'Total_Sqft'])\n",
        "prop_type_col = get_col(df, ['Property_Type', 'Property type', 'property_type', 'Type', 'propertytype'])\n",
        "price_psq_col = get_col(df, ['Price_per_SqFt', 'Price_per_sqft', 'price_per_sqft', 'price_per_sqft_in_lakhs'])\n",
        "price_per_sqft_computed = False\n",
        "\n",
        "print(f\"Using columns -> price: {price_col}, area: {area_col}, property_type: {prop_type_col}, price_per_sqft: {price_psq_col}\")\n",
        "\n",
        "# Compute Price_per_SqFt if missing and if price & area exist\n",
        "if price_psq_col is None:\n",
        "    if price_col and area_col:\n",
        "        # convert to numeric and avoid division by zero / NaN\n",
        "        df[price_col] = pd.to_numeric(df[price_col], errors='coerce')\n",
        "        df[area_col]  = pd.to_numeric(df[area_col], errors='coerce')\n",
        "        # If Price is in lakhs and area is sqft, this will be lakhs per sqft — it's fine as a relative measure.\n",
        "        df['Price_per_SqFt'] = df[price_col] / df[area_col]\n",
        "        price_psq_col = 'Price_per_SqFt'\n",
        "        price_per_sqft_computed = True\n",
        "        print(\"Computed Price_per_SqFt as\", price_psq_col)\n",
        "    else:\n",
        "        print(\"Price_per_SqFt not available and cannot be computed (missing price or area).\")\n",
        "\n",
        "# Ensure numeric types for plotting\n",
        "for col in [price_col, area_col, price_psq_col]:\n",
        "    if col and col in df.columns:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# 1) Distribution of property prices\n",
        "if price_col and price_col in df.columns:\n",
        "    plt.figure(figsize=(10,5))\n",
        "    sns.histplot(df[price_col].dropna(), kde=True)\n",
        "    plt.title(\"Distribution of Property Prices (\" + price_col + \")\")\n",
        "    plt.xlabel(\"Price\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Skipping price distribution plot: price column not found.\")\n",
        "\n",
        "# 2) Distribution of property sizes (area)\n",
        "if area_col and area_col in df.columns:\n",
        "    plt.figure(figsize=(10,5))\n",
        "    sns.histplot(df[area_col].dropna(), kde=True)\n",
        "    plt.title(\"Distribution of Property Sizes (\" + area_col + \")\")\n",
        "    plt.xlabel(\"Area (sqft)\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Skipping area distribution plot: area column not found.\")\n",
        "\n",
        "# 3) How does price per sqft vary by property type?\n",
        "if price_psq_col and price_psq_col in df.columns and prop_type_col and prop_type_col in df.columns:\n",
        "    plt.figure(figsize=(12,6))\n",
        "    sns.boxplot(data=df, x=prop_type_col, y=price_psq_col)\n",
        "    plt.title(f\"Price per Sqft ({price_psq_col}) by Property Type ({prop_type_col})\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "elif price_psq_col and price_psq_col in df.columns:\n",
        "    print(\"Property type column not found; showing overall distribution of price per sqft instead.\")\n",
        "    plt.figure(figsize=(10,5))\n",
        "    sns.histplot(df[price_psq_col].dropna(), kde=True)\n",
        "    plt.title(\"Distribution of Price per Sqft (\" + price_psq_col + \")\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Skipping price-per-sqft by property type: necessary columns missing.\")\n",
        "\n",
        "# 4) Relationship between property size and price (scatter + correlation)\n",
        "if price_col and price_col in df.columns and area_col and area_col in df.columns:\n",
        "    plt.figure(figsize=(10,6))\n",
        "    sns.scatterplot(data=df, x=area_col, y=price_col, alpha=0.4)\n",
        "    plt.title(f\"Property Size ({area_col}) vs Price ({price_col})\")\n",
        "    plt.xlabel(\"Area (sqft)\")\n",
        "    plt.ylabel(\"Price\")\n",
        "    plt.show()\n",
        "    corr = df[area_col].corr(df[price_col])\n",
        "    print(f\"Correlation between {area_col} and {price_col}: {corr:.4f}\")\n",
        "else:\n",
        "    print(\"Skipping size vs price scatter: missing area or price column.\")\n",
        "\n",
        "# 5) Outliers: detect using IQR for price per sqft and area (if present)\n",
        "def detect_outliers_iqr(series):\n",
        "    s = series.dropna()\n",
        "    q1 = s.quantile(0.25)\n",
        "    q3 = s.quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    lower = q1 - 1.5 * iqr\n",
        "    upper = q3 + 1.5 * iqr\n",
        "    out = s[(s < lower) | (s > upper)]\n",
        "    return lower, upper, out\n",
        "\n",
        "if price_psq_col and price_psq_col in df.columns:\n",
        "    low, high, outliers = detect_outliers_iqr(df[price_psq_col])\n",
        "    print(f\"Price per sqft ({price_psq_col}) IQR bounds: lower={low:.3f}, upper={high:.3f}, outliers_count={len(outliers)}\")\n",
        "    plt.figure(figsize=(10,4))\n",
        "    sns.boxplot(x=df[price_psq_col].dropna())\n",
        "    plt.title(\"Boxplot — Price per Sqft (\" + price_psq_col + \")\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Skipping price per sqft outlier detection: column not found.\")\n",
        "\n",
        "if area_col and area_col in df.columns:\n",
        "    low_a, high_a, outliers_a = detect_outliers_iqr(df[area_col])\n",
        "    print(f\"Area ({area_col}) IQR bounds: lower={low_a:.1f}, upper={high_a:.1f}, outliers_count={len(outliers_a)}\")\n",
        "    plt.figure(figsize=(10,4))\n",
        "    sns.boxplot(x=df[area_col].dropna())\n",
        "    plt.title(\"Boxplot — Area (\" + area_col + \")\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Skipping area outlier detection: area column not found.\")\n",
        "\n",
        "# OPTIONAL: If property_type missing, show top few property types if variant exists\n",
        "if not prop_type_col:\n",
        "    # try to infer a 'type' from other columns like 'Property Category' variants\n",
        "    alt_prop_type_col = get_col(df, ['Property Category', 'Category', 'House_Type'])\n",
        "    if alt_prop_type_col:\n",
        "        print(f\"Using alternative property-type column: {alt_prop_type_col}\")\n",
        "        prop_type_col = alt_prop_type_col\n",
        "    else:\n",
        "        print(\"No property-type column found in dataset; some grouped analyses skipped.\")\n",
        "\n",
        "# Summary of findings placeholders (replace with actual numeric summaries as needed)\n",
        "print(\"\\nSummary (quick stats):\")\n",
        "for col in [price_col, area_col, price_psq_col]:\n",
        "    if col and col in df.columns:\n",
        "        print(f\" - {col}: count={df[col].notna().sum()}, mean={df[col].mean():.3f}, median={df[col].median():.3f}, std={df[col].std():.3f}\")\n"
      ],
      "metadata": {
        "id": "zSw_VhwNih19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights**\n",
        "\n",
        "\n",
        "*   Distribution in prices, Area, Price in Sqft, Outliers and Relationship\n",
        "*   IQR to detect the prices of per sqft and Area.\n",
        "\n"
      ],
      "metadata": {
        "id": "a3luX6pYNRll"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Location-based Analysis\n"
      ],
      "metadata": {
        "id": "56DgRQNbmsYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------\n",
        "# Load original dataset for this specific EDA cell to use original column names and unscaled values\n",
        "# This is done because 'State' was one-hot encoded and numerical columns were scaled in previous preprocessing.\n",
        "df_original_for_eda = pd.read_csv(\"/content/india_housing_prices.csv\", engine='python')\n",
        "\n",
        "# 1. Average price per sq ft by state\n",
        "# ------------------------------------------\n",
        "avg_price_sqft_state = (\n",
        "    df_original_for_eda.groupby(\"State\")[\"Price_per_SqFt\"]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        "    .sort_values(\"Price_per_SqFt\", ascending=False)\n",
        ")\n",
        "\n",
        "print(\"\\nAverage Price per Sq Ft by State:\")\n",
        "print(avg_price_sqft_state)\n",
        "\n",
        "\n",
        "# ------------------------------------------\n",
        "# 2. Average property price by city\n",
        "# ------------------------------------------\n",
        "avg_price_city = (\n",
        "    df_original_for_eda.groupby(\"City\")[\"Price_in_Lakhs\"]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        "    .sort_values(\"Price_in_Lakhs\", ascending=False)\n",
        ")\n",
        "\n",
        "print(\"\\nAverage Property Price by City:\")\n",
        "print(avg_price_city)\n",
        "\n",
        "\n",
        "# ------------------------------------------\n",
        "# 3. Median age of properties by locality\n",
        "# ------------------------------------------\n",
        "# Use 'Age_of_Property' directly as it exists in the original dataset and represents age\n",
        "if \"Age_of_Property\" not in df_original_for_eda.columns:\n",
        "    raise ValueError(\"Dataset must contain 'Age_of_Property' column for this analysis.\")\n",
        "\n",
        "median_age_locality = (\n",
        "    df_original_for_eda.groupby(\"Locality\")[\"Age_of_Property\"]\n",
        "    .median()\n",
        "    .reset_index()\n",
        "    .sort_values(\"Age_of_Property\")\n",
        ")\n",
        "\n",
        "print(\"\\nMedian Age of Properties by Locality:\")\n",
        "print(median_age_locality)\n",
        "\n",
        "\n",
        "# ------------------------------------------\n",
        "# 4. BHK distribution across cities\n",
        "# ------------------------------------------\n",
        "bhk_distribution = (\n",
        "    df_original_for_eda.groupby([\"City\", \"BHK\"])\n",
        "    .size()\n",
        "    .reset_index(name=\"Count\")\n",
        "    .sort_values([\"City\", \"BHK\"])\n",
        ")\n",
        "\n",
        "print(\"\\nBHK Distribution Across Cities:\")\n",
        "print(bhk_distribution)\n",
        "\n",
        "\n",
        "# ------------------------------------------\n",
        "# 5. Price trends for top 5 most expensive localities\n",
        "# ------------------------------------------\n",
        "# First find average price for each locality\n",
        "locality_avg_price = (\n",
        "    df_original_for_eda.groupby(\"Locality\")[\"Price_in_Lakhs\"]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        "    .sort_values(\"Price_in_Lakhs\", ascending=False)\n",
        ")\n",
        "\n",
        "# Select top 5\n",
        "top_5_localities = locality_avg_price.head(5)[\"Locality\"].tolist()\n",
        "\n",
        "print(\"\\nTop 5 Most Expensive Localities:\")\n",
        "print(top_5_localities)\n",
        "\n",
        "# Filter data for only these localities\n",
        "df_top5_eda = df_original_for_eda[df_original_for_eda[\"Locality\"].isin(top_5_localities)]\n",
        "\n",
        "# Use 'Year_Built' for price trends\n",
        "if \"Year_Built\" in df_top5_eda.columns:\n",
        "    price_trends = (\n",
        "        df_top5_eda.groupby([\"Locality\", \"Year_Built\"])[\"Price_in_Lakhs\"]\n",
        "        .mean()\n",
        "        .reset_index()\n",
        "        .sort_values([\"Locality\", \"Year_Built\"])\n",
        "    )\n",
        "else:\n",
        "    price_trends = \"Dataset has no Year_Built column to compute trends.\"\n",
        "\n",
        "print(\"\\nPrice Trends for Top 5 Localities:\")\n",
        "print(price_trends)\n"
      ],
      "metadata": {
        "id": "OKOCi5pvih6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights**\n",
        "\n",
        "\n",
        "*   Location Based Analysis  Average price per sq ft by state\n",
        "*   Average property price by city\n",
        "*   Median age by properties by Locality.\n",
        "*   BHK distribution Across cities.\n",
        "*   Price trends of top 5 localities.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Xq6WP_XuRxre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Step 1: Load your dataset\n",
        "# Replace the filename with the actual path to your CSV\n",
        "df_original_for_eda = pd.read_csv(\"india_housing_prices.csv\", engine='python')\n",
        "\n",
        "# Step 2: Inspect the first few rows to confirm column names\n",
        "print(df_original_for_eda.head())\n",
        "print(df_original_for_eda.columns)\n"
      ],
      "metadata": {
        "id": "wbNBzv5KEgGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Relationship & Correlation - Full Analysis Code"
      ],
      "metadata": {
        "id": "g_JXdT9bpyBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------\n",
        "# 1. Correlation among all numeric features\n",
        "# -----------------------------------------------------------\n",
        "numeric_df = df.select_dtypes(include=['int64', 'float64'])\n",
        "\n",
        "correlation_matrix = numeric_df.corr()\n",
        "\n",
        "print(\"\\nCorrelation Between Numeric Features:\")\n",
        "print(correlation_matrix)\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 2. Relationship: Nearby Schools vs Price per sq ft\n",
        "# -----------------------------------------------------------\n",
        "if \"Nearby_Schools\" in df.columns:\n",
        "    school_relation = (\n",
        "        df.groupby(\"Nearby_Schools\")[\"Price_per_SqFt\"] # Corrected column name\n",
        "        .mean()\n",
        "        .reset_index()\n",
        "        .sort_values(\"Price_per_SqFt\", ascending=False) # Corrected column name\n",
        "    )\n",
        "else:\n",
        "    school_relation = \"Column 'Nearby_Schools' not found.\"\n",
        "\n",
        "print(\"\\nNearby Schools vs Price per Sq Ft:\")\n",
        "print(school_relation)\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 3. Relationship: Nearby Hospitals vs Price per sq ft\n",
        "# -----------------------------------------------------------\n",
        "if \"Nearby_Hospitals\" in df.columns:\n",
        "    hospital_relation = (\n",
        "        df.groupby(\"Nearby_Hospitals\")[\"Price_per_SqFt\"] # Corrected column name\n",
        "        .mean()\n",
        "        .reset_index()\n",
        "        .sort_values(\"Price_per_SqFt\", ascending=False) # Corrected column name\n",
        "    )\n",
        "else:\n",
        "    hospital_relation = \"Column 'Nearby_Hospitals' not found.\"\n",
        "\n",
        "print(\"\\nNearby Hospitals vs Price per Sq Ft:\")\n",
        "print(hospital_relation)\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 4. Price variation by furnished status\n",
        "# -----------------------------------------------------------\n",
        "if \"Furnished_Status\" in df.columns: # Corrected column name\n",
        "    furnished_price = (\n",
        "        df.groupby(\"Furnished_Status\")[\"Price_in_Lakhs\"] # Corrected column name\n",
        "        .mean()\n",
        "        .reset_index()\n",
        "        .sort_values(\"Price_in_Lakhs\", ascending=False) # Corrected column name\n",
        "    )\n",
        "else:\n",
        "    furnished_price = \"Column 'Furnished_Status' not found.\"\n",
        "\n",
        "print(\"\\nPrice Variation by Furnished Status:\")\n",
        "print(furnished_price)\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 5. Price per sq ft by property facing direction\n",
        "# -----------------------------------------------------------\n",
        "if \"Facing\" in df.columns:\n",
        "    facing_price_sqft = (\n",
        "        df.groupby(\"Facing\")[\"Price_per_SqFt\"] # Corrected column name\n",
        "        .mean()\n",
        "        .reset_index()\n",
        "        .sort_values(\"Price_per_SqFt\", ascending=False) # Corrected column name\n",
        "    )\n",
        "else:\n",
        "    facing_price_sqft = \"Column 'Facing' not found.\"\n",
        "\n",
        "print(\"\\nPrice per Sq Ft by Property Facing Direction:\")\n",
        "print(facing_price_sqft)\n"
      ],
      "metadata": {
        "id": "3TfmAyZkih-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights**\n",
        "Feature correlation and Realtionship between the properties and neaby facilities like -: school, Hospital, Feature status of the locality ."
      ],
      "metadata": {
        "id": "1n0-M5A7TfHg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Investment / Amenities / Ownership Analysis — Full Python Code"
      ],
      "metadata": {
        "id": "y-PWXRrYq3C9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------------\n",
        "# 1. Properties by Owner Type\n",
        "# ---------------------------------------------------------------------\n",
        "if \"Owner_Type\" in df.columns:\n",
        "    owner_type_count = df[\"Owner_Type\"].value_counts().reset_index()\n",
        "    owner_type_count.columns = [\"Owner_Type\", \"Count\"]\n",
        "else:\n",
        "    owner_type_count = \"Column 'Owner_Type' not found.\"\n",
        "\n",
        "print(\"\\nProperties by Owner Type:\")\n",
        "print(owner_type_count)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 2. Properties by Availability Status\n",
        "# ---------------------------------------------------------------------\n",
        "if \"Availability_Status\" in df.columns: # Corrected 'Availability' to 'Availability_Status'\n",
        "    availability_count = df[\"Availability_Status\"].value_counts().reset_index()\n",
        "    availability_count.columns = [\"Availability_Status\", \"Count\"]\n",
        "else:\n",
        "    availability_count = \"Column 'Availability_Status' not found.\" # Corrected message\n",
        "\n",
        "print(\"\\nProperties by Availability Status:\")\n",
        "print(availability_count)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 3. Parking Space vs Property Price\n",
        "# ---------------------------------------------------------------------\n",
        "parking_cols = [col for col in df.columns if \"parking\" in col.lower() or \"Parking\" in col]\n",
        "\n",
        "if parking_cols:\n",
        "    parking_col = parking_cols[0]\n",
        "    parking_price_relation = (\n",
        "        df.groupby(parking_col)[\"Price_in_Lakhs\"] # Corrected 'Price' to 'Price_in_Lakhs'\n",
        "        .mean()\n",
        "        .reset_index()\n",
        "        .sort_values(\"Price_in_Lakhs\", ascending=False) # Corrected 'Price' to 'Price_in_Lakhs'\n",
        "    )\n",
        "else:\n",
        "    parking_price_relation = \"No parking-related column found.\"\n",
        "\n",
        "print(\"\\nParking Space vs Property Price:\")\n",
        "print(parking_price_relation)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 4. Amenities vs Price per Sq Ft\n",
        "# ---------------------------------------------------------------------\n",
        "amenity_keywords = [\"Pool\", \"Gym\", \"Garden\", \"Lift\", \"Security\", \"Club\", \"Play\", \"Parking\"]\n",
        "\n",
        "amenity_cols = [\n",
        "    col for col in df.columns\n",
        "    if any(keyword.lower() in col.lower() for keyword in amenity_keywords)\n",
        "]\n",
        "\n",
        "amenity_price_effect = {}\n",
        "\n",
        "if amenity_cols:\n",
        "    for col in amenity_cols:\n",
        "        # Check if 'Amenities' column exists before trying to access it\n",
        "        if col == \"Amenities\": # 'Amenities' itself is a string of comma-separated values, not a binary amenity\n",
        "            # This amenity column is not suitable for binary grouping in this way\n",
        "            continue\n",
        "\n",
        "        if df[col].nunique() <= 2:  # Only binary amenities\n",
        "            effect = df.groupby(col)[\"Price_per_SqFt\"].mean().reset_index() # Corrected 'Price_per_sqft'\n",
        "            amenity_price_effect[col] = effect\n",
        "else:\n",
        "    amenity_price_effect = \"No amenity columns found.\"\n",
        "\n",
        "print(\"\\nAmenities' Effect on Price per Sq Ft:\")\n",
        "print(amenity_price_effect)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 5. Public Transport Accessibility vs Price per Sq Ft / Investment Potential\n",
        "# ---------------------------------------------------------------------\n",
        "transport_cols = [col for col in df.columns if \"Transport\" in col or \"Metro\" in col or \"Bus\" in col]\n",
        "\n",
        "if transport_cols:\n",
        "    transport_col = transport_cols[0]  # Using the first relevant column\n",
        "\n",
        "    # Relationship with price per sq ft\n",
        "    transport_price_relation = (\n",
        "        df.groupby(transport_col)[\"Price_per_SqFt\"] # Corrected 'Price_per_sqft'\n",
        "        .mean()\n",
        "        .reset_index()\n",
        "        .sort_values(\"Price_per_SqFt\", ascending=False) # Corrected 'Price_per_sqft'\n",
        "    )\n",
        "\n",
        "    # Investment potential = price appreciation or price difference across levels\n",
        "    # Here we use Price_per_SqFt as proxy since appreciation data isn't available\n",
        "    investment_potential = transport_price_relation.copy()\n",
        "else:\n",
        "    transport_price_relation = \"No transport-related column found.\"\n",
        "    investment_potential = \"No transport-related column found.\"\n",
        "\n",
        "print(\"\\nPublic Transport Accessibility vs Price per Sq Ft:\")\n",
        "print(transport_price_relation)\n",
        "\n",
        "print(\"\\nPublic Transport Accessibility vs Investment Potential:\")\n",
        "print(investment_potential)\n"
      ],
      "metadata": {
        "id": "i62fNsMyqUH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights**\n",
        "Investment and ownership Analysis of getting a property in locality for the transport Assessbility , Parking space and other feature per in sqft ."
      ],
      "metadata": {
        "id": "YD0dpmQ3UIgG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATA CLEANING"
      ],
      "metadata": {
        "id": "hpjLMRvOspn7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Common Real Estate Dataset Analyses**\n",
        "\n",
        "\n",
        "* Descriptive statistics: Average, median, and distribution of housing prices by city, neighborhood, or property type.\n",
        "\n",
        "*  Trend analysis: Price changes over time (monthly/quarterly/yearly).\n",
        "\n",
        "*  Feature impact: How variables like square footage, number of bedrooms, or proximity to amenities affect price.\n",
        "\n",
        "*  Segmentation: Grouping properties into clusters (e.g., affordable, mid-range, luxury).\n",
        "\n",
        "*  Predictive modeling: Building regression or machine learning models to forecast housing prices.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Cr7S8c_0s9EB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Setup ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib # Import joblib to save models\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression # For classification\n",
        "from sklearn.ensemble import RandomForestClassifier # For classification\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc # Added classification metrics\n",
        "\n",
        "# Optional: statsmodels for detailed regression summaries\n",
        "import statsmodels.api as sm\n",
        "\n",
        "pd.set_option('display.float_format', lambda x: f'{x:,.2f}')\n",
        "sns.set(style='whitegrid', context='talk')\n",
        "\n",
        "# --- Load dataset ---\n",
        "# Using the preprocessed dataset from Step 1\n",
        "df = pd.read_csv('processed_housing_data.csv')\n",
        "\n",
        "# Ensure 'Good_Investment' is int for classification\n",
        "df['Good_Investment'] = df['Good_Investment'].astype(int)\n",
        "\n",
        "# --- Basic normalization of columns (adjust these mappings to your actual schema) ---\n",
        "# The preprocessor pipeline handles these for modeling\n",
        "\n",
        "# --- Quick data health check ---\n",
        "print('Shape:', df.shape)\n",
        "print('Missing values (top 10):\\n', df.isna().sum().sort_values(ascending=False).head(10))\n",
        "\n",
        "# --- Predictive modeling (Classification for Good_Investment) ---\n",
        "print('\\n=== Predictive modeling (Classification for Good_Investment) ===')\n",
        "\n",
        "target = 'Good_Investment' # Changed target to classification label\n",
        "\n",
        "# Select features\n",
        "# Using columns that are likely to be good predictors and are not targets or IDs\n",
        "# Exclude original Price_in_Lakhs as it's correlated with the target through CAGR_5Y\n",
        "# Exclude 'Estimated_Price_5Y' and 'CAGR_5Y' as they are derived from price and used to create the target\n",
        "# Exclude 'ID', 'Locality', 'City', 'State' as their frequency encoded versions or one-hot encoded versions are used.\n",
        "# Exclude 'Amenities' as Amenities_Count is derived.\n",
        "# Exclude 'Price_per_SqFt_calculated' if original 'Price_per_SqFt' is kept.\n",
        "\n",
        "feature_candidates = [\n",
        "    'BHK', 'Size_in_SqFt', 'Price_per_SqFt', 'Year_Built', 'Furnished_Status',\n",
        "    'Floor_No', 'Total_Floors', 'Age_of_Property', 'Nearby_Schools', 'Nearby_Hospitals',\n",
        "    'Public_Transport_Accessibility', 'Parking_Space', 'Security', 'Amenities_Count',\n",
        "    'Facing', 'Owner_Type', 'Locality_Freq', 'City_Freq', 'Has_Parking', 'Has_Security',\n",
        "    'School_Density_Score'\n",
        "]\n",
        "# Add one-hot encoded state and availability status features, dynamically check existing columns\n",
        "state_cols = [col for col in df.columns if col.startswith('State_')]\n",
        "availability_cols = [col for col in df.columns if col.startswith('Availability_Status_')]\n",
        "property_type_cols = [col for col in df.columns if col.startswith('Property_Type_')]\n",
        "\n",
        "feature_candidates.extend(state_cols)\n",
        "feature_candidates.extend(availability_cols)\n",
        "feature_candidates.extend(property_type_cols)\n",
        "\n",
        "# Ensure no target-related columns or highly correlated identifiers are in features\n",
        "features = [f for f in feature_candidates if f in df.columns and f not in ['ID', target, 'Estimated_Price_5Y', 'CAGR_5Y']]\n",
        "\n",
        "X_cols = features\n",
        "\n",
        "# Drop rows with missing target\n",
        "model_df = df[X_cols + [target]].copy()\n",
        "model_df = model_df[model_df[target].notna()]\n",
        "\n",
        "# Split numeric and categorical\n",
        "numeric_features = model_df[X_cols].select_dtypes(include=np.number).columns.tolist()\n",
        "categorical_features = model_df[X_cols].select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "# Preprocess\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ],\n",
        "    remainder='passthrough' # Keep other columns if any\n",
        ")\n",
        "\n",
        "X = model_df[X_cols]\n",
        "y = model_df[target]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y # Stratify for classification target\n",
        ")\n",
        "\n",
        "# Model 1: Logistic Regression\n",
        "logreg = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression(solver='liblinear', random_state=42, class_weight='balanced')) # Changed to LogisticRegression and added class_weight\n",
        "])\n",
        "\n",
        "# Model 2: Random Forest Classifier\n",
        "rf_classifier = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(\n",
        "        n_estimators=100, max_depth=None, random_state=42, n_jobs=-1, class_weight='balanced'\n",
        "    )) # Changed to RandomForestClassifier and added class_weight\n",
        "])\n",
        "\n",
        "# Fit and evaluate Logistic Regression\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred_logreg = logreg.predict(X_test)\n",
        "y_prob_logreg = logreg.predict_proba(X_test)[:, 1] # For ROC curve\n",
        "\n",
        "print('\\nLogistic Regression performance (Classification):')\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred_logreg))\n",
        "print('Classification Report:\\n', classification_report(y_test, y_pred_logreg))\n",
        "\n",
        "# Fit and evaluate Random Forest Classifier\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "y_pred_rf_classifier = rf_classifier.predict(X_test)\n",
        "y_prob_rf_classifier = rf_classifier.predict_proba(X_test)[:, 1] # For ROC curve\n",
        "\n",
        "print('\\nRandom Forest Classifier performance (Classification):')\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred_rf_classifier))\n",
        "print('Classification Report:\\n', classification_report(y_test, y_pred_rf_classifier))\n",
        "\n",
        "# Save the best classification model (RandomForestClassifier in this case) for the Streamlit app\n",
        "joblib.dump(rf_classifier, 'investment_model.pkl')\n",
        "print(\"Saved investment_model.pkl\")\n",
        "\n",
        "# Pass variables to the next cell for plotting\n",
        "# Using Random Forest Classifier results for the evaluation plot\n",
        "global y_test_for_plot, y_pred_for_plot, y_prob_for_plot\n",
        "y_test_for_plot = y_test\n",
        "y_pred_for_plot = y_pred_rf_classifier\n",
        "y_prob_for_plot = y_prob_rf_classifier\n",
        "\n",
        "print('\\n=== Done ===')\n"
      ],
      "metadata": {
        "id": "m1yRBfE2qUVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights**\n",
        "\n",
        "\n",
        "*   Data Cleaning : descrpitive Analysis of average, Median and distribution in prices by city, houses and Neighbourhood.\n",
        "\n",
        "*  Trend Analysis price of housing change over time in month, year and annually.\n",
        "\n",
        "*   Feature Impact: like hous design, bedroom location and afforable price for amenities to stay and get assessbility.\n",
        "\n",
        "*  Segmentaion of the proerties on the prices and according to price in sqft like -: Average , Median and Luxury.\n",
        "\n",
        "*  Predicting regressiona nd classification model to get the accuracy of the property prices.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "X3S6Zf4nU357"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATA VISUALIZATION\n",
        "\n",
        "\n",
        "*  Heatmaps showing price variation across regions.\n",
        "\n",
        "*  Boxplots comparing property types.\n",
        "\n",
        "*  Time-series line charts of average prices.\n",
        "\n",
        "*  Scatter plots of price vs. square footage.\n",
        "\n"
      ],
      "metadata": {
        "id": "jfgK8QhtuT9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt # Import matplotlib.pyplot\n",
        "import seaborn as sns\n",
        "import pandas as pd # Ensure pandas is imported\n",
        "\n",
        "# --- 1. Heatmap: price variation across regions by Property Type ---\n",
        "# Average price by city and property type\n",
        "pivot = df.pivot_table(values='Price_in_Lakhs',\n",
        "                       index='City',\n",
        "                       columns='Property_Type',\n",
        "                       aggfunc='mean')\n",
        "\n",
        "plt.figure(figsize=(15, 10)) # Increased figure size for better readability\n",
        "sns.heatmap(pivot, cmap=\"YlOrRd\", annot=True, fmt=\".1f\") # Added annot=True and fmt for values\n",
        "plt.title(\"Heatmap of Average Housing Prices (Lakhs) by City & Property Type\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- 2. Boxplots: comparing property types ---\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=df, x='Property_Type', y='Price_in_Lakhs')\n",
        "plt.title(\"Price Distribution by Property Type\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- 3. Time-series line chart: average prices by Year_Built ---\n",
        "# Use Year_Built as a proxy for time trend if a transaction date is not available\n",
        "# Note: This represents prices of properties built in a given year, not market transaction trends over time.\n",
        "yearly_prices = df.groupby('Year_Built')['Price_in_Lakhs'].mean().reset_index()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.lineplot(data=yearly_prices, x='Year_Built', y='Price_in_Lakhs')\n",
        "plt.title(\"Average Housing Prices (Lakhs) by Year Built\")\n",
        "plt.xlabel(\"Year Built\")\n",
        "plt.ylabel(\"Average Price (Lakhs)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- 4. Scatter plot: price vs. square footage ---\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=df, x='Size_in_SqFt', y='Price_in_Lakhs', alpha=0.6)\n",
        "plt.title(\"Scatter Plot of Price (Lakhs) vs. Square Footage\")\n",
        "plt.xlabel(\"Square Footage\")\n",
        "plt.ylabel(\"Price (Lakhs)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GFhI2ejuqUY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights**\n",
        "\n",
        "\n",
        "*  Data Visualization Heatmaps showing price variation across regions.\n",
        "\n",
        "*  Boxplots comparing property types and price per sqft.\n",
        "\n",
        "*  Time-series line charts of average prices.\n",
        "\n",
        "*  Scatter plots of price vs. square footage.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HGSHwhEmXZWa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 3 : MODEL DEVELOPMENT"
      ],
      "metadata": {
        "id": "zS7kpsUsyVe5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TEST AND TRAIN THE MODEL"
      ],
      "metadata": {
        "id": "CrHQqKDivrI6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trained classification model with high accuracy for investment prediction.\n"
      ],
      "metadata": {
        "id": "CRcnsKBRvxsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"india_housing_prices.csv\")\n",
        "print(df.columns)"
      ],
      "metadata": {
        "id": "7usJkdXfSai5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# 1) Price-based Rule\n",
        "# -----------------------\n",
        "median_price = df[\"Price_in_Lakhs\"].median()\n",
        "df[\"rule_price\"] = df[\"Price_in_Lakhs\"] <= median_price\n",
        "\n",
        "# -----------------------\n",
        "# 2) PPSF (Locality Median)\n",
        "# -----------------------\n",
        "df[\"locality_ppsf_median\"] = df.groupby(\"Locality\")[\"Price_per_SqFt\"].transform(\"median\")\n",
        "df[\"rule_ppsf\"] = df[\"Price_per_SqFt\"] <= df[\"locality_ppsf_median\"]\n",
        "\n",
        "# -----------------------\n",
        "# 3) Multi-Factor Score\n",
        "# -----------------------\n",
        "df[\"locality_area_median\"] = df.groupby(\"Locality\")[\"Size_in_SqFt\"].transform(\"median\")\n",
        "\n",
        "df[\"score\"] = (\n",
        "    (df[\"BHK\"] >= 3).astype(int) +\n",
        "    (df[\"Availability_Status\"].isin([\"Ready to Move\", \"ReadyToMove\"])).astype(int) +\n",
        "    (df[\"Size_in_SqFt\"] >= df[\"locality_area_median\"]).astype(int)\n",
        ")\n",
        "\n",
        "df[\"rule_multifactor\"] = df[\"score\"] >= 2\n",
        "\n",
        "# -----------------------\n",
        "# 4) Final Label\n",
        "# -----------------------\n",
        "df[\"Good_Investment\"] = (\n",
        "    df[\"rule_price\"] |\n",
        "    df[\"rule_ppsf\"] |\n",
        "    df[\"rule_multifactor\"]\n",
        ").map({True: \"Good\", False: \"Bad\"})\n",
        "\n",
        "df.to_csv(\"housing_dataset_with_labels.csv\", index=False)\n",
        "\n",
        "print(\"✔ Good Investment target created successfully!\")\n"
      ],
      "metadata": {
        "id": "EaL32PuPTA12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights**\n",
        "Model Development where to train and test the model\n",
        "price based rule, Locality median, Mulity factor score and Label ."
      ],
      "metadata": {
        "id": "vhA39TZhYb9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib\n",
        "\n",
        "# Load updated dataset\n",
        "df = pd.read_csv(\"housing_dataset_with_labels.csv\")\n",
        "\n",
        "# Encode categorical columns\n",
        "cat_cols = [\"State\", \"City\", \"Locality\", \"Property_Type\",\n",
        "            \"Furnished_Status\", \"Facing\", \"Owner_Type\",\n",
        "            \"Availability_Status\"]\n",
        "\n",
        "for col in cat_cols:\n",
        "    df[col] = df[col].astype(str)\n",
        "    df[col] = LabelEncoder().fit_transform(df[col])\n",
        "\n",
        "# Create target variable\n",
        "y = df[\"Good_Investment\"].map({\"Good\": 1, \"Bad\": 0})\n",
        "\n",
        "# Select features\n",
        "X = df[[\n",
        "    \"Size_in_SqFt\",\n",
        "    \"Price_in_Lakhs\",\n",
        "    \"Price_per_SqFt\",\n",
        "    \"BHK\",\n",
        "    \"City\",\n",
        "    \"Locality\",\n",
        "    \"Availability_Status\"\n",
        "]]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train model\n",
        "model = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=12,\n",
        "    min_samples_split=4,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(\"🔥 Model Accuracy:\", acc)\n",
        "print(\"\\n📊 Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Save model\n",
        "joblib.dump(model, \"good_investment_model.pkl\")\n"
      ],
      "metadata": {
        "id": "6Uiwi5AaTBBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights**\n",
        "Classification Model prediction and investment with the accuracy of 98% for good investment"
      ],
      "metadata": {
        "id": "h7Ds2gPdZKyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
        "\n",
        "# Use the variables made available from the previous cell's classification model\n",
        "# Check if variables are defined\n",
        "if 'y_test_for_plot' in globals() and 'y_pred_for_plot' in globals() and 'y_prob_for_plot' in globals():\n",
        "    y_test = y_test_for_plot\n",
        "    y_pred = y_pred_for_plot\n",
        "    y_prob = y_prob_for_plot\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    plt.figure(figsize=(6,4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.show()\n",
        "\n",
        "    # Classification report\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "    # ROC Curve\n",
        "    # y_prob is already calculated and available from previous cell\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.2f}\")\n",
        "    plt.plot([0,1],[0,1],'--',color='gray')\n",
        "    plt.title(\"ROC Curve\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "elif 'y_test' not in globals(): # More specific check for initial state\n",
        "    print(\"Error: Classification model variables (y_test, y_pred, y_prob) are not defined. Please ensure the model training cell (m1yRBfE2qUVi) was executed successfully.\")\n",
        "else:\n",
        "    print(\"Error: An unexpected issue occurred with variable definitions. Please check the model training cell.\")\n"
      ],
      "metadata": {
        "id": "A_hVDNB5qUcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights**\n",
        "\n",
        "\n",
        "*  Condusion Matrix to predict the actual data\n",
        "*  ROC curve to predict the true and false poistive rate of the investment.\n",
        "\n"
      ],
      "metadata": {
        "id": "fY-r_6-pZguF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regression model with low RMSE for price forecasting.\n"
      ],
      "metadata": {
        "id": "0AXP2KibxIEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Assume y_test and y_pred are available\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"R²: {r2:.2f}\")\n",
        "\n",
        "# Residuals\n",
        "residuals = y_test - y_pred\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.scatterplot(x=y_pred, y=residuals, alpha=0.6)\n",
        "plt.axhline(0, color='red', linestyle='--')\n",
        "plt.title(\"Residuals vs Predicted Prices\")\n",
        "plt.xlabel(\"Predicted Price\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Distribution of residuals\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.histplot(residuals, bins=40, kde=True)\n",
        "plt.title(\"Distribution of Residuals\")\n",
        "plt.xlabel(\"Residual\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mvaIVLuXw2kF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights**\n",
        "* Regression model with low RMSE for price forcasting.\n",
        "* Residuals Vs Predicted price."
      ],
      "metadata": {
        "id": "qq5dSjmBabJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9_DpyndlaajC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 4: ML FLOW INTEGRATION"
      ],
      "metadata": {
        "id": "YP7IWYfx0lfy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ML Integration means connecting Machine Learning models with an application so that the model can be used in the real world.\n",
        "\n",
        "\n",
        "\n",
        "*  Loading the trained model\n",
        "\n",
        "*  Sending user input to the model\n",
        "\n",
        "*  Getting predictions from the model\n",
        "\n",
        "*  Showing the results to the user (UI, app, dashboard)\n",
        "\n"
      ],
      "metadata": {
        "id": "AGNqT17lNRI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mlflow\n"
      ],
      "metadata": {
        "id": "EFcM2eszw205"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")"
      ],
      "metadata": {
        "id": "zd4oIGcU-g9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Step 4: MLflow Integration\n",
        "Track experiments with different models, log parameters/metrics/artifacts,\n",
        "and use the MLflow Model Registry to manage best models.\n",
        "\"\"\"\n",
        "\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import numpy as np # Import numpy for np.sqrt\n",
        "import joblib # Import joblib to save the best model\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Load dataset (example)\n",
        "# -----------------------------\n",
        "df = pd.read_csv(\"india_housing_prices.csv\")\n",
        "\n",
        "# Adjust column names to match your dataset\n",
        "X = df[[\"Size_in_SqFt\", \"BHK\", \"Age_of_Property\"]]\n",
        "y = df[\"Price_in_Lakhs\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Set MLflow experiment\n",
        "# -----------------------------\n",
        "mlflow.set_tracking_uri(\"./mlruns\")  # Changed to local directory for tracking\n",
        "mlflow.set_experiment(\"HousingPricePrediction\")\n",
        "\n",
        "# -----------------------------\n",
        "# 3. Define models to compare\n",
        "# -----------------------------\n",
        "models = {\n",
        "    \"LinearRegression\": LinearRegression(),\n",
        "    \"DecisionTree\": DecisionTreeRegressor(max_depth=5, random_state=42),\n",
        "    \"RandomForest\": RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42),\n",
        "}\n",
        "\n",
        "# -----------------------------\n",
        "# 4. Train, evaluate, log runs\n",
        "# -----------------------------\n",
        "for model_name, model in models.items():\n",
        "    with mlflow.start_run(run_name=model_name):\n",
        "        # Fit model\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Metrics\n",
        "        # Fix: Calculate RMSE by taking the square root of MSE, as 'squared' parameter is not recognized.\n",
        "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "        # Log parameters (if available)\n",
        "        if hasattr(model, \"get_params\"):\n",
        "            params = model.get_params()\n",
        "            for p, v in params.items():\n",
        "                mlflow.log_param(p, v)\n",
        "\n",
        "        # Log metrics\n",
        "        mlflow.log_metric(\"rmse\", rmse)\n",
        "        mlflow.log_metric(\"r2\", r2)\n",
        "\n",
        "        # Log model artifact\n",
        "        mlflow.sklearn.log_model(model, \"model\")\n",
        "\n",
        "        print(f\"{model_name}: RMSE={rmse:.3f}, R2={r2:.3f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# 5. Register best model and save locally for Streamlit\n",
        "# -----------------------------\n",
        "# Find best run by lowest RMSE\n",
        "client = MlflowClient()\n",
        "experiment = client.get_experiment_by_name(\"HousingPricePrediction\")\n",
        "runs = client.search_runs([experiment.experiment_id], order_by=[\"metrics.rmse ASC\"], max_results=1)\n",
        "\n",
        "best_run = runs[0]\n",
        "best_run_id = best_run.info.run_id\n",
        "best_model_name = \"HousingPriceModel\"\n",
        "\n",
        "# Register model\n",
        "result = mlflow.register_model(\n",
        "    f\"runs:/{best_run_id}/model\",\n",
        "    best_model_name\n",
        ")\n",
        "\n",
        "# Transition to Production stage\n",
        "client.transition_model_version_stage(\n",
        "    name=best_model_name,\n",
        "    version=result.version,\n",
        "    stage=\"Production\"\n",
        ")\n",
        "\n",
        "print(f\"Best model registered: {best_model_name}, version {result.version}, stage=Production\")\n",
        "\n",
        "# Load the best model from MLflow and save it locally for the Streamlit app\n",
        "loaded_best_model = mlflow.sklearn.load_model(f\"runs:/{best_run_id}/model\")\n",
        "joblib.dump(loaded_best_model, 'regression_model.pkl')\n",
        "print(\"Saved regression_model.pkl from the best MLflow run.\")\n"
      ],
      "metadata": {
        "id": "r3ocvkqhG32-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights**\n",
        "\n",
        "* ML flow integration application install to manage best model, artifacts, Registry of the model.\n",
        "\n",
        "* ML flow experiment and define model to compare"
      ],
      "metadata": {
        "id": "WPWDZgj7bh7A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STREAMLIT APP"
      ],
      "metadata": {
        "id": "iON0f6vpLNkV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Streamlit app is a simple, interactive web application built using Python, mainly used for:\n",
        "\n",
        "✅ Data Science\n",
        "✅ Machine Learning Projects\n",
        "✅ Dashboards\n",
        "✅ Model Deployment\n",
        "✅ Data Visualizations\n",
        "\n",
        "It lets you turn your Python code into a beautiful web interface—without needing HTML, CSS, or JavaScript."
      ],
      "metadata": {
        "id": "e-gslHWRLVum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "id": "12WUYsNwiaHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "import altair as alt\n",
        "from datetime import datetime\n",
        "\n",
        "# Optional: MLflow integration for loading registered models\n",
        "try:\n",
        "    import mlflow\n",
        "    import mlflow.sklearn\n",
        "    from mlflow.tracking import MlflowClient\n",
        "    MLFLOW_AVAILABLE = True\n",
        "except Exception:\n",
        "    MLFLOW_AVAILABLE = False\n",
        "\n",
        "# -----------------------------\n",
        "# Config\n",
        "# -----------------------------\n",
        "CSV_PATH = \"india_housing_prices.csv\"  # change to your data path\n",
        "FEATURES = [\"Area_sqft\", \"BHK\", \"Age_of_Property\"]  # adjust to your columns\n",
        "TARGET_PRICE = \"Price_in_Lakhs\"  # numeric target in lakhs\n",
        "CATEGORICALS = [\"State\", \"City\", \"Locality\"]\n",
        "DATE_COL = \"Listing_Date\"  # change if you have listing_date\n",
        "MODEL_NAME_REG = \"HousingPriceModel\"  # MLflow registered regression model\n",
        "MODEL_NAME_CLS = \"InvestmentClassifier\"  # MLflow registered classifier (if you have one)\n",
        "\n",
        "# Growth assumptions for 5-year projection (simple compounding)\n",
        "DEFAULT_CAGR = 0.06  # 6% annual\n",
        "YEARS_FORWARD = 5\n",
        "\n",
        "# -----------------------------\n",
        "# Helpers\n",
        "# -----------------------------\n",
        "@st.cache_data\n",
        "def load_data(path: str) -> pd.DataFrame:\n",
        "    if not os.path.exists(path):\n",
        "        st.error(f\"Dataset not found at: {path}\")\n",
        "        return pd.DataFrame()\n",
        "    df = pd.read_csv(path)\n",
        "    # normalize optional\n",
        "    # Coerce numerics for safety\n",
        "    for col in [TARGET_PRICE, \"Area_sqft\", \"BHK\", \"Age_of_Property\"]:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "    # parse dates if present\n",
        "    if DATE_COL in df.columns:\n",
        "        df[DATE_COL] = pd.to_datetime(df[DATE_COL], errors=\"coerce\")\n",
        "    return df\n",
        "\n",
        "def get_mlflow_model(model_name: str):\n",
        "    if not MLFLOW_AVAILABLE:\n",
        "        return None, None\n",
        "    try:\n",
        "        mlflow.set_tracking_uri(os.environ.get(\"MLFLOW_TRACKING_URI\", \"http://127.0.0.1:5000\"))\n",
        "        client = MlflowClient()\n",
        "        versions = client.search_model_versions(f\"name='{model_name}'\")\n",
        "        # pick latest in Production\n",
        "        prod = [v for v in versions if v.current_stage == \"Production\"]\n",
        "        if not prod:\n",
        "            return None, None\n",
        "        # latest by last_updated_timestamp\n",
        "        best = sorted(prod, key=lambda x: x.last_updated_timestamp, reverse=True)[0]\n",
        "        uri = f\"models:/{model_name}/{best.current_stage}\"\n",
        "        model = mlflow.sklearn.load_model(uri)\n",
        "        return model, best\n",
        "    except Exception as e:\n",
        "        st.warning(f\"Could not load MLflow model '{model_name}': {e}\")\n",
        "        return None, None\n",
        "\n",
        "def compute_feature_importance(model, feature_names):\n",
        "    # Supports scikit-learn tree-based models or linear models\n",
        "    try:\n",
        "        if hasattr(model, \"feature_importances_\"):\n",
        "            imp = model.feature_importances_\n",
        "            return pd.DataFrame({\"feature\": feature_names, \"importance\": imp}).sort_values(\"importance\", ascending=False)\n",
        "        elif hasattr(model, \"coef_\"):\n",
        "            coef = model.coef_\n",
        "            if np.ndim(coef) == 1:\n",
        "                imp = np.abs(coef)\n",
        "            else:\n",
        "                imp = np.abs(coef).mean(axis=0)\n",
        "            return pd.DataFrame({\"feature\": feature_names, \"importance\": imp}).sort_values(\"importance\", ascending=False)\n",
        "        else:\n",
        "            return pd.DataFrame({\"feature\": feature_names, \"importance\": np.nan})\n",
        "    except Exception:\n",
        "        return pd.DataFrame({\"feature\": feature_names, \"importance\": np.nan})\n",
        "\n",
        "def baseline_regressor_predict(area, bhk, age, base_ppsf=10000.0):\n",
        "    # Simple heuristic: price = ppsf * area * adjustment\n",
        "    # Adjust for bhk and age\n",
        "    bhk_adj = 1.0 + 0.08 * max(0, (bhk - 2))\n",
        "    age_adj = max(0.6, 1.0 - 0.02 * max(0, age - 5))\n",
        "    price = base_ppsf * area * bhk_adj * age_adj\n",
        "    # Convert to lakhs\n",
        "    return price / 100000.0\n",
        "\n",
        "def baseline_classifier_score(price_lakhs, city_avg_lakhs):\n",
        "    # Score 0-1 based on how the price compares to city average\n",
        "    # Cheaper than average -> higher score\n",
        "    if city_avg_lakhs is None or np.isnan(city_avg_lakhs):\n",
        "        return 0.5\n",
        "    ratio = price_lakhs / max(1e-6, city_avg_lakhs)\n",
        "    score = np.clip(1.2 - ratio, 0.0, 1.0)\n",
        "    return score\n",
        "\n",
        "def project_price_5y(current_price_lakhs, cagr=DEFAULT_CAGR, years=YEARS_FORWARD):\n",
        "    return current_price_lakhs * ((1 + cagr) ** years)\n",
        "\n",
        "def city_avg_price(df: pd.DataFrame, city: str) -> float:\n",
        "    if df.empty or TARGET_PRICE not in df.columns or \"City\" not in df.columns:\n",
        "        return np.nan\n",
        "    sub = df[(df[\"City\"] == city) & df[TARGET_PRICE].notna()]\n",
        "    if sub.empty:\n",
        "        return np.nan\n",
        "    return sub[TARGET_PRICE].mean()\n",
        "\n",
        "# -----------------------------\n",
        "# UI\n",
        "# -----------------------------\n",
        "st.set_page_config(page_title=\"Housing Investment Insights\", layout=\"wide\")\n",
        "st.title(\"Housing Investment Insights\")\n",
        "\n",
        "df = load_data(CSV_PATH)\n",
        "if df.empty:\n",
        "    st.stop()\n",
        "\n",
        "with st.sidebar:\n",
        "    st.header(\"Filter dataset\")\n",
        "    states = sorted(df[\"State\"].dropna().unique().tolist()) if \"State\" in df.columns else []\n",
        "    cities = sorted(df[\"City\"].dropna().unique().tolist()) if \"City\" in df.columns else []\n",
        "    localities = sorted(df[\"Locality\"].dropna().unique().tolist()) if \"Locality\" in df.columns else []\n",
        "\n",
        "    sel_state = st.selectbox(\"State\", options=[\"All\"] + states)\n",
        "    sel_city = st.selectbox(\"City\", options=[\"All\"] + cities)\n",
        "    sel_locality = st.selectbox(\"Locality\", options=[\"All\"] + localities)\n",
        "\n",
        "    min_area = st.number_input(\"Min area (sqft)\", min_value=0, value=0, step=50)\n",
        "    max_area = st.number_input(\"Max area (sqft)\", min_value=0, value=0, step=50, help=\"0 means no upper bound\")\n",
        "    min_price = st.number_input(\"Min price (lakhs)\", min_value=0.0, value=0.0, step=1.0)\n",
        "    max_price = st.number_input(\"Max price (lakhs)\", min_value=0.0, value=0.0, step=1.0, help=\"0 means no upper bound\")\n",
        "    sel_bhk = st.multiselect(\"BHK\", options=sorted(df[\"BHK\"].dropna().unique().tolist()) if \"BHK\" in df.columns else [], default=[])\n",
        "\n",
        "# Apply filters\n",
        "filtered = df.copy()\n",
        "if sel_state != \"All\" and \"State\" in filtered.columns:\n",
        "    filtered = filtered[filtered[\"State\"] == sel_state]\n",
        "if sel_city != \"All\" and \"City\" in filtered.columns:\n",
        "    filtered = filtered[filtered[\"City\"] == sel_city]\n",
        "if sel_locality != \"All\" and \"Locality\" in filtered.columns:\n",
        "    filtered = filtered[filtered[\"Locality\"] == sel_locality]\n",
        "if \"Area_sqft\" in filtered.columns and min_area > 0:\n",
        "    filtered = filtered[filtered[\"Area_sqft\"] >= min_area]\n",
        "if \"Area_sqft\" in filtered.columns and max_area > 0:\n",
        "    filtered = filtered[filtered[\"Area_sqft\"] <= max_area]\n",
        "if TARGET_PRICE in filtered.columns and min_price > 0:\n",
        "    filtered = filtered[filtered[TARGET_PRICE] >= min_price]\n",
        "if TARGET_PRICE in filtered.columns and max_price > 0:\n",
        "    filtered = filtered[filtered[TARGET_PRICE] <= max_price]\n",
        "if \"BHK\" in filtered.columns and sel_bhk:\n",
        "    filtered = filtered[filtered[\"BHK\"].isin(sel_bhk)]\n",
        "\n",
        "st.subheader(\"Filtered dataset preview\")\n",
        "st.dataframe(filtered.head(50), use_container_width=True)\n",
        "\n",
        "# -----------------------------\n",
        "# User input form: property details\n",
        "# -----------------------------\n",
        "st.subheader(\"Enter property details\")\n",
        "colA, colB, colC, colD = st.columns(4)\n",
        "with colA:\n",
        "    in_state = st.selectbox(\"Input state\", options=states if states else [\"Unknown\"])\n",
        "with colB:\n",
        "    in_city = st.selectbox(\"Input city\", options=cities if cities else [\"Unknown\"])\n",
        "with colC:\n",
        "    in_locality = st.text_input(\"Input locality\", value=(localities[0] if localities else \"\"))\n",
        "with colD:\n",
        "    in_bhk = st.number_input(\"BHK\", min_value=1, max_value=10, value=2, step=1)\n",
        "\n",
        "colE, colF, colG, colH = st.columns(4)\n",
        "with colE:\n",
        "    in_area = st.number_input(\"Area (sqft)\", min_value=100, max_value=20000, value=1000, step=50)\n",
        "with colF:\n",
        "    in_age = st.number_input(\"Age of Property (years)\", min_value=0, max_value=100, value=5, step=1)\n",
        "with colG:\n",
        "    in_current_price = st.number_input(\"Current price (lakhs)\", min_value=0.0, value=50.0, step=0.5)\n",
        "with colH:\n",
        "    in_cagr = st.number_input(\"Assumed CAGR for 5 years\", min_value=0.0, max_value=0.25, value=DEFAULT_CAGR, step=0.01)\n",
        "\n",
        "# -----------------------------\n",
        "# Models: load MLflow models or baseline\n",
        "# -----------------------------\n",
        "reg_model, reg_meta = get_mlflow_model(MODEL_NAME_REG) if MLFLOW_AVAILABLE else (None, None)\n",
        "cls_model, cls_meta = get_mlflow_model(MODEL_NAME_CLS) if MLFLOW_AVAILABLE else (None, None)\n",
        "\n",
        "# Prepare input vector\n",
        "def input_vector():\n",
        "    vec = pd.DataFrame([{\n",
        "        \"Area_sqft\": in_area,\n",
        "        \"BHK\": in_bhk,\n",
        "        \"Age_of_Property\": in_age\n",
        "    }])\n",
        "    return vec\n",
        "\n",
        "# -----------------------------\n",
        "# Predictions\n",
        "# -----------------------------\n",
        "st.markdown(\"---\")\n",
        "st.subheader(\"Results\")\n",
        "\n",
        "# Regression: Estimated Price after 5 Years\n",
        "if reg_model is not None:\n",
        "    try:\n",
        "        pred_current_lakhs = float(reg_model.predict(input_vector())[0])\n",
        "    except Exception as e:\n",
        "        st.warning(f\"Regression model prediction failed, using baseline. Error: {e}\")\n",
        "        pred_current_lakhs = baseline_regressor_predict(in_area, in_bhk, in_age)\n",
        "else:\n",
        "    pred_current_lakhs = baseline_regressor_predict(in_area, in_bhk, in_age)\n",
        "\n",
        "pred_5y_lakhs = project_price_5y(pred_current_lakhs, cagr=in_cagr, years=YEARS_FORWARD)\n",
        "\n",
        "# Classification: Is this a Good Investment?\n",
        "if cls_model is not None:\n",
        "    try:\n",
        "        # If model has predict_proba, use probability for confidence\n",
        "        if hasattr(cls_model, \"predict_proba\"):\n",
        "            proba = cls_model.predict_proba(input_vector())\n",
        "            confidence = float(np.max(proba))\n",
        "            label = int(cls_model.predict(input_vector())[0])\n",
        "        else:\n",
        "            # fallback: decision_function or predict\n",
        "            label = int(cls_model.predict(input_vector())[0])\n",
        "            confidence = 0.5\n",
        "    except Exception as e:\n",
        "        st.warning(f\"Classifier prediction failed, using heuristic. Error: {e}\")\n",
        "        city_avg = city_avg_price(df, in_city)\n",
        "        score = baseline_classifier_score(pred_current_lakhs, city_avg)\n",
        "        label = 1 if score >= 0.5 else 0\n",
        "        confidence = float(score)\n",
        "else:\n",
        "    city_avg = city_avg_price(df, in_city)\n",
        "    score = baseline_classifier_score(pred_current_lakhs, city_avg)\n",
        "    label = 1 if score >= 0.5 else 0\n",
        "    confidence = float(score)\n",
        "\n",
        "inv_text = \"Good Investment\" if label == 1 else \"Not Ideal Right Now\"\n",
        "\n",
        "met1, met2, met3 = st.columns(3)\n",
        "with met1:\n",
        "    st.metric(\"Predicted current fair price (lakhs)\", f\"{pred_current_lakhs:,.2f}\")\n",
        "with met2:\n",
        "    st.metric(\"Estimated price after 5 years (lakhs)\", f\"{pred_5y_lakhs:,.2f}\")\n",
        "with met3:\n",
        "    st.metric(\"Classification\", inv_text)\n",
        "\n",
        "st.caption(f\"Model confidence: {confidence:0.2f}\")\n",
        "\n",
        "# Feature importance\n",
        "st.subheader(\"Model feature importance\")\n",
        "reg_imp = compute_feature_importance(reg_model, FEATURES) if reg_model is not None else pd.DataFrame({\"feature\": FEATURES, \"importance\": [np.nan]*len(FEATURES)})\n",
        "st.dataframe(reg_imp, use_container_width=True)\n",
        "if reg_imp[\"importance\"].notna().any():\n",
        "    chart_imp = alt.Chart(reg_imp).mark_bar().encode(\n",
        "        x=alt.X(\"importance:Q\", title=\"Importance\"),\n",
        "        y=alt.Y(\"feature:N\", sort=\"-x\", title=\"Feature\")\n",
        "    ).properties(height=200)\n",
        "    st.altair_chart(chart_imp, use_container_width=True)\n",
        "\n",
        "# -----------------------------\n",
        "# Visual insights\n",
        "# -----------------------------\n",
        "st.markdown(\"---\")\n",
        "st.subheader(\"Visual insights\")\n",
        "\n",
        "# Location-wise heatmap (City vs BHK by avg price)\n",
        "if {\"City\", \"BHK\", TARGET_PRICE}.issubset(filtered.columns):\n",
        "    heat = (\n",
        "        filtered.dropna(subset=[\"City\", \"BHK\", TARGET_PRICE])\n",
        "        .groupby([\"City\", \"BHK\"], as_index=False)[TARGET_PRICE]\n",
        "        .mean()\n",
        "        .rename(columns={TARGET_PRICE: \"AvgPriceLakhs\"})\n",
        "    )\n",
        "    heat_chart = alt.Chart(heat).mark_rect().encode(\n",
        "        x=alt.X(\"City:N\", title=\"City\"),\n",
        "        y=alt.Y(\"BHK:O\", title=\"BHK\"),\n",
        "        color=alt.Color(\"AvgPriceLakhs:Q\", title=\"Avg Price (Lakhs)\", scale=alt.Scale(scheme=\"viridis\")),\n",
        "        tooltip=[\"City\", \"BHK\", \"AvgPriceLakhs\"]\n",
        "    ).properties(height=300)\n",
        "    st.altair_chart(heat_chart, use_container_width=True)\n",
        "else:\n",
        "    st.info(\"Heatmap requires City, BHK, and Price_in_Lakhs columns.\")\n",
        "\n",
        "# Trend charts: monthly average prices by city\n",
        "if DATE_COL in filtered.columns and \"City\" in filtered.columns and TARGET_PRICE in filtered.columns:\n",
        "    trend = (\n",
        "        filtered.dropna(subset=[DATE_COL, \"City\", TARGET_PRICE])\n",
        "        .assign(month=lambda d: d[DATE_COL].dt.to_period(\"M\").dt.to_timestamp()))\n",
        "\n",
        "\n",
        "    # Select top 8 cities by recent avg\n",
        "    recent = trend[trend[\"month\"] == trend[\"month\"].max()].sort_values(\"AvgPriceLakhs\", ascending=False)[\"City\"].head(8).tolist()\n",
        "    trend_sel = trend[trend[\"City\"].isin(recent)]\n",
        "    line = alt.Chart(trend_sel).mark_line(point=True).encode(\n",
        "        x=alt.X(\"month:T\", title=\"Month\"),\n",
        "        y=alt.Y(\"AvgPriceLakhs:Q\", title=\"Avg Price (Lakhs)\"),\n",
        "        color=\"City:N\",\n",
        "        tooltip=[\"City\", \"month\", \"AvgPriceLakhs\"]\n",
        "    ).properties(height=350)\n",
        "    st.altair_chart(line, use_container_width=True)\n",
        "else:\n",
        "    st.info(\"Trend chart requires Listing_Date, City, and Price_in_Lakhs columns.\")\n",
        "\n",
        "# PPSF by state (bar)\n",
        "if {\"State\", \"Area_sqft\", TARGET_PRICE}.issubset(filtered.columns):\n",
        "    ppsf_df = filtered.dropna(subset=[\"State\", \"Area_sqft\", TARGET_PRICE]).copy()\n",
        "    ppsf_df[\"Price_per_SqFt\"] = (ppsf_df[TARGET_PRICE] * 100000.0) / ppsf_df[\"Area_sqft\"]\n",
        "    ppsf_state = ppsf_df.groupby(\"State\", as_index=False)[\"Price_per_SqFt\"].mean().sort_values(\"Price_per_SqFt\", ascending=False)\n",
        "    bar_ppsf = alt.Chart(ppsf_state).mark_bar().encode(\n",
        "        x=alt.X(\"Price_per_SqFt:Q\", title=\"Avg Price per Sq Ft\"),\n",
        "        y=alt.Y(\"State:N\", sort=\"-x\"),\n",
        "        tooltip=[\"State\", \"Price_per_SqFt\"]\n",
        "    ).properties(height=400)\n",
        "    st.altair_chart(bar_ppsf, use_container_width=True)\n",
        "else:\n",
        "    st.info(\"PPSF chart requires State, Area_sqft, and Price_in_Lakhs columns.\")\n",
        "\n",
        "# -----------------------------\n",
        "# Confidence and rationale\n",
        "# -----------------------------\n",
        "st.markdown(\"---\")\n",
        "st.subheader(\"Model confidence and rationale\")\n",
        "city_avg_val = city_avg_price(df, in_city)\n",
        "st.write(f\"- City average price (lakhs): {city_avg_val:,.2f}\" if not np.isnan(city_avg_val) else \"- City average price (lakhs): N/A\")\n",
        "st.write(f\"- Input BHK: {in_bhk}, Area: {in_area} sqft, Age: {in_age} years\")\n",
        "st.write(f\"- Assumed CAGR for projection: {in_cagr*100:.1f}% over {YEARS_FORWARD} years\")\n",
        "\n",
        "st.success(\"Tip: Compare the predicted current fair price vs. your listed price and the city average. If the predicted fair price is below city average and projection looks strong, confidence will be higher.\")\n",
        "\n",
        "# Footer\n",
        "st.markdown(\"---\")\n",
        "st.caption(\"This app integrates dataset filters, model predictions, visual insights, and MLflow-based model management (when available). Replace feature names or MLflow model names to match your environment.\")"
      ],
      "metadata": {
        "id": "4GG3kq4XL5df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights**\n",
        "* Streamlit App install to Predict the model and Growth prediction after 5 years.\n",
        "\n",
        "* monthly avaerage charges by cities and locality."
      ],
      "metadata": {
        "id": "TUPzVBLbejD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Target Variables"
      ],
      "metadata": {
        "id": "A4yj5l8hOTaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------\n",
        "#   FULL CODE: Future Price Prediction (All 4 Methods Combined)\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# 1️⃣  Fixed Rate Future Price Prediction (default = 8%)\n",
        "# ---------------------------------------------------------------\n",
        "def future_price_fixed(current_price, rate=0.08, years=5):\n",
        "    \"\"\"\n",
        "    Simple fixed rate appreciation model.\n",
        "    \"\"\"\n",
        "    return current_price * ((1 + rate) ** years)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# 2️⃣  Location-Based Growth Model\n",
        "# ---------------------------------------------------------------\n",
        "location_growth_rates = {\n",
        "    \"Mumbai\": 0.09,\n",
        "    \"Delhi\": 0.06,\n",
        "    \"Bangalore\": 0.08,\n",
        "    \"Hyderabad\": 0.10,\n",
        "    \"Pune\": 0.07,\n",
        "    \"Chennai\": 0.06,\n",
        "    \"Kolkata\": 0.05\n",
        "}\n",
        "\n",
        "def future_price_location(current_price, location, years=5):\n",
        "    \"\"\"\n",
        "    Predict future price using location-specific growth rate.\n",
        "    \"\"\"\n",
        "    rate = location_growth_rates.get(location, 0.06)  # Default = 6%\n",
        "    return current_price * ((1 + rate) ** years)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# 3️⃣  Property-Type Based Growth Model\n",
        "# ---------------------------------------------------------------\n",
        "property_growth_rates = {\n",
        "    \"Apartment\": 0.07,\n",
        "    \"Villa\": 0.10,\n",
        "    \"Plot\": 0.12,\n",
        "    \"Independent House\": 0.08\n",
        "}\n",
        "\n",
        "def future_price_property(current_price, property_type, years=5):\n",
        "    \"\"\"\n",
        "    Predict future price using property-type growth rate.\n",
        "    \"\"\"\n",
        "    rate = property_growth_rates.get(property_type, 0.07)  # Default = 7%\n",
        "    return current_price * ((1 + rate) ** years)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# 4️⃣  ML Model Based Future Price Prediction (Best Approach)\n",
        "# ---------------------------------------------------------------\n",
        "def future_price_ml(model, input_features, current_price, years=5):\n",
        "    \"\"\"\n",
        "    Predict appreciation rate using ML model, then compute future price.\n",
        "    \"\"\"\n",
        "    predicted_rate = model.predict(input_features)[0]   # Example: 0.085 (8.5%)\n",
        "    future_price = current_price * ((1 + predicted_rate) ** years)\n",
        "\n",
        "    return future_price, predicted_rate\n",
        "\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# 5️⃣  Combined Function (Runs All Methods)\n",
        "# ---------------------------------------------------------------\n",
        "def calculate_future_prices(current_price, location, property_type, input_features=None, ml_model=None):\n",
        "    \"\"\"\n",
        "    Returns a dictionary with all future price predictions.\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "\n",
        "    # ---- METHOD 1: FIXED RATE (8%) ----\n",
        "    results[\"Fixed Method (8%)\"] = future_price_fixed(current_price)\n",
        "\n",
        "    # ---- METHOD 2: LOCATION BASED ----\n",
        "    results[\"Location Method\"] = future_price_location(current_price, location)\n",
        "\n",
        "    # ---- METHOD 3: PROPERTY TYPE BASED ----\n",
        "    results[\"Property Type Method\"] = future_price_property(current_price, property_type)\n",
        "\n",
        "    # ---- METHOD 4: ML BASED ----\n",
        "    if ml_model is not None and input_features is not None:\n",
        "        ml_price, ml_rate = future_price_ml(ml_model, input_features, current_price)\n",
        "        results[\"ML Method Future Price\"] = ml_price\n",
        "        results[\"ML Predicted Growth Rate\"] = ml_rate\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# 6️⃣  EXAMPLE USAGE (Comment out in Streamlit)\n",
        "# ---------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Example input features\n",
        "    input_data = pd.DataFrame({\n",
        "        \"Area\": [1200],\n",
        "        \"BHK\": [3],\n",
        "        \"Bathrooms\": [2],\n",
        "        \"Location\": [\"Mumbai\"],\n",
        "        \"Property_Type\": [\"Apartment\"]\n",
        "    })\n",
        "\n",
        "    # Load ML appreciation model (if available)\n",
        "    try:\n",
        "        ml_model = joblib.load(\"growth_rate_model.pkl\")\n",
        "    except:\n",
        "        ml_model = None\n",
        "        print(\"⚠️ ML growth model not found. Skipping ML-based prediction.\")\n",
        "\n",
        "    # Run all predictions\n",
        "    results = calculate_future_prices(\n",
        "        current_price = 5000000,\n",
        "        location = \"Hyderabad\",\n",
        "        property_type = \"Apartment\",\n",
        "        input_features = input_data,\n",
        "        ml_model = ml_model\n",
        "    )\n",
        "\n",
        "    # Print results\n",
        "    for method, value in results.items():\n",
        "        if \"Rate\" in method:\n",
        "            print(f\"{method}: {value * 100:.2f}%\")\n",
        "        else:\n",
        "            print(f\"{method}: ₹ {value:,.0f}\")\n"
      ],
      "metadata": {
        "id": "zM0Vq9g7OReJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"india_housing_prices.csv\")\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# Rule 1: Price ≤ Median Price → GOOD\n",
        "# -----------------------------------------------------\n",
        "median_price = df[\"Price_in_Lakhs\"].median()\n",
        "df[\"rule_price\"] = df[\"Price_in_Lakhs\"] <= median_price\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# Rule 2: PPSF ≤ Locality Median → GOOD\n",
        "# -----------------------------------------------------\n",
        "df[\"locality_ppsf_median\"] = df.groupby(\"Locality\")[\"Price_per_SqFt\"].transform(\"median\")\n",
        "df[\"rule_ppsf\"] = df[\"Price_per_SqFt\"] <= df[\"locality_ppsf_median\"]\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# Rule 3: Multi-Factor Score\n",
        "# Conditions:\n",
        "#   +1 if BHK ≥ 3\n",
        "#   +1 if Ready to Move\n",
        "#   +1 if Area ≥ locality median area\n",
        "# -----------------------------------------------------\n",
        "df[\"locality_area_median\"] = df.groupby(\"Locality\")[\"Size_in_SqFt\"].transform(\"median\")\n",
        "\n",
        "df[\"score\"] = (\n",
        "    (df[\"BHK\"] >= 3).astype(int) +\n",
        "    (df[\"Availability_Status\"].isin([\"Ready to Move\", \"ReadyToMove\"])).astype(int) +\n",
        "    (df[\"Size_in_SqFt\"] >= df[\"locality_area_median\"]).astype(int)\n",
        ")\n",
        "\n",
        "df[\"rule_multi\"] = df[\"score\"] >= 2     # Threshold\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# FINAL TARGET: GOOD if any rule is TRUE\n",
        "# -----------------------------------------------------\n",
        "df[\"Good_Investment\"] = (\n",
        "    df[\"rule_price\"] |\n",
        "    df[\"rule_ppsf\"] |\n",
        "    df[\"rule_multi\"]\n",
        ").map({True: \"Good\", False: \"Bad\"})\n",
        "\n",
        "# Save\n",
        "df.to_csv(\"housing_dataset_with_labels.csv\", index=False)\n",
        "\n",
        "print(\"✔ 'Good_Investment' column created successfully!\")\n"
      ],
      "metadata": {
        "id": "RzwKndiTORuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib\n",
        "\n",
        "# Load updated dataset\n",
        "df = pd.read_csv(\"housing_dataset_with_labels.csv\")\n",
        "\n",
        "# Categorical columns to encode\n",
        "cat_cols = [\n",
        "    \"State\", \"City\", \"Locality\", \"Property_Type\",\n",
        "    \"Furnished_Status\", \"Facing\", \"Owner_Type\",\n",
        "    \"Availability_Status\"\n",
        "]\n",
        "\n",
        "# Encode categoricals\n",
        "for col in cat_cols:\n",
        "    df[col] = df[col].astype(str)\n",
        "    df[col] = LabelEncoder().fit_transform(df[col])\n",
        "\n",
        "# Target\n",
        "y = df[\"Good_Investment\"].map({\"Good\": 1, \"Bad\": 0})\n",
        "\n",
        "# Features\n",
        "X = df[[\n",
        "    \"Size_in_SqFt\",\n",
        "    \"Price_in_Lakhs\",\n",
        "    \"Price_per_SqFt\",\n",
        "    \"BHK\",\n",
        "    \"City\",\n",
        "    \"Locality\",\n",
        "    \"Availability_Status\"\n",
        "]]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train model\n",
        "model = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=12,\n",
        "    min_samples_split=4,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(\"🔥 Model Accuracy:\", acc)\n",
        "print(\"\\n📊 Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Save model\n",
        "joblib.dump(model, \"good_investment_model.pkl\")\n"
      ],
      "metadata": {
        "id": "4hQBVlh4ORyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CONCLUSION\n",
        "* Data Processing to check and handle missing values and remove duplicates.\n",
        "* Data Cleaning of categorical features and missing values.\n",
        "* Data Visulaization Heatmap , Trends in prices and price in sqft, Scatter plot and box plot.\n",
        "* Model development to test and train the model to get the accuracy of the model and predict the outcome of the investment on properties.\n",
        "* ML flow integration\n",
        "* Streamlit application for reister the model and predict the Model of the housing prices ."
      ],
      "metadata": {
        "id": "8LNDWxACUt6X"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x2jvP9g_OR2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IplmnFEvOR6B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}